# -*- coding: utf-8 -*-
"""RAM_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PqcrPyDv3VUbtM-YsISQDX0bFL6egPa-

# Reconstruct-Anything-Model (RAM)

RAM is a non-iterative **lightweight foundation model** for solving imaging inverse problems given by

$$y = N(Ax)$$

where $y$ are the observed measurements, $A$ is a linear forward operator (acquisition physics), $N$ represents noise (Gaussian, Poisson, Poisson-Gaussian, etc), and $x$ is the ground-truth image that we want to recover from $y$.

The model has been trained on a large set of operators $A$ (inpainting, downsamplings, MRI, CT, motion blur, etc.) and noise models $N$ (Gaussian, Poisson-Gaussian).

RAM was developed using the [deepinverse library](https://deepinv.github.io/deepinv/), which provides a large set of imaging operators $A$ and noise models $N$, see [here](https://deepinv.github.io/deepinv/user_guide/physics/physics.html) for a detailed list.

### Installing libraries

We begin by installing `deepinv` and `ram` libraries.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# pip install git+https://github.com/matthieutrs/ram

"""### Download demo image and generate measurements

In this demo we use image inpainting as the forward operator. You can find **a list of other forward operators** [here](https://deepinv.github.io/deepinv/user_guide/physics/physics.html), including MRI, CT, motion blur, pansharpen, etc. You can also try **changing the noise model** by choosing one from [this list](https://deepinv.github.io/deepinv/user_guide/physics/physics.html#noise-distributions).
"""

import deepinv as dinv

# run on cpu (Colab doesn't have GPU by default)
device = 'cpu'


# load butterfly image
url = dinv.utils.get_image_url("butterfly.png")
x = dinv.utils.load_url_image(url=url, img_size=256).to(device)

# create forward operator
physics = dinv.physics.Inpainting(tensor_size=(3, 256, 256), mask=.5,
                                  noise_model=dinv.physics.GaussianNoise(.05), device=device)

# generate measurement
y = physics(x)

# plot
dinv.utils.plot([x, y], ["Original", "Measurement"])

"""### Load RAM


Pretrained weights are downloaded automatically from a HuggingFace repository.
RAM requires the measurements $y$ (a `torch.tensor`), the forward model $A$ and noise parameters (both encapsulated in `physics`).

"""

from ram import RAM


# Load the pretrained model
model = RAM(device=device)

# run inference
x_hat = model(y, physics=physics)

# plot
dinv.utils.plot([x, y, x_hat], ["Original", "Measurement", "Reconstruction"])

"""## Finetuning RAM

Despite its good performance across a varied set of imaging tasks, RAM can be easily finetuned to obtain the best performance in new tasks or datasets.

Finetuning can be done in a fully self-supervised way, ie. **without ground-truth references**, combining clever losses that only require measurements $y$ developed specifically for inverse problems.

We can finetune RAM with:
- single measurement $y$
- batch of measurements $y$
- dataset $\{y_i\}_{i=1}^N$
- supervised dataset $\{x_i, y_i\}_{i=1}^N$

Here we finetune with a single $y$, but you can check [these demos](https://github.com/matthieutrs/ram/blob/main/ram/demo/finetuning_dataset.py) for more details on how to use a full dataset.


We finetune the parameters $\theta$ of RAM with the following objective:

$$
\arg \min_{\theta} \mathcal{L}_{\text{MC}}(f_{\theta}(y),y) + \lambda \mathcal{L}_{\text{NULL}}(f_{\theta}(y),y)
$$

where the measurement consistency loss $\mathcal{L}_{\text{MC}}$ is [simple consistency](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.MCLoss.html#deepinv.loss.MCLoss) $\|f(y)-y\|^2$ if there is no noise, a [splitting loss](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SplittingLoss.html#deepinv.loss.SplittingLoss) if the noise is unknown (but assumed independent across pixels), [SURE](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SureGaussianLoss.html) if the noise is Gaussian or Poisson-Gaussian. The $\mathcal{L}_{\text{NULL}}$ is designed to enable learning in the nullspace of the operator $A$, and is set as the [equivariant imaging](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.EILoss.html) loss, using `transform='shift'` by default.

You can **check this [YouTube tutorial](https://youtube.com/playlist?list=PLrflIVF5S9hDfFKdH3yAgNrLnP2JF6WBN&si=t46JCApNlTSsuNDz)** if you want to learn more about self-supervised losses.

In this example, we finetune the model to demosaicing problem
"""

from ram import finetune

physics = dinv.physics.Demosaicing(img_size=(256, 256), noise_model=dinv.physics.GaussianNoise(.05))

y = physics(x)

# run zero-shot inference
x_zero_shot = model(y, physics=physics)

# use a GPU for faster finetuning
# we only finetune for 1 gradient steps here due to CPU speed constraints
model = finetune(model, y, physics, max_iter=1, noise_loss='SURE', transform='shift', device=device)

# run inference
x_finetuned = model(y, physics=physics)

# compute PSNR
zero_shot_psnr = dinv.metric.PSNR()(x, x_zero_shot).item()
finetuned_psnr = dinv.metric.PSNR()(x, x_finetuned).item()

print(f"PSNR zero-shot {zero_shot_psnr:2f} dB, finetuned {finetuned_psnr:2f} dB")

# plot
dinv.utils.plot([x, y, x_zero_shot, x_finetuned], ["Original", "Measurement", "Zero-Shot", "Finetuned"])